# Customer-Churn-Analysis-using-PySpark-
•	Designed scalable data ingestion pipelines using PySpark to process 3591 customer records with 21 attributes, ensuring 94% schema compliance and type optimization and engineered ETL workflows to clean, transform, and categorize telecom churn data.
•	Built feature engineering pipelines with Spark MLlib, improving vectorized dataset preparation and reducing training time by 30% for predictive models.
•	Developed robust correlation analysis processes, identifying churn predictors like International Plan (+26% correlation) and Customer Service Calls (+21%).
•	Optimized distributed model training (Decision Tree, Random Forest, Gradient Boost) achieving ~85% model accuracy on stratified samples.
•	Implemented modular data workflows, enhancing reusability and scalability for large-scale customer analytics in cloud/HDFS environments.
